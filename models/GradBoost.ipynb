{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Обучение градиентного бустинга с подбором гиперпараметров, использую optuna."
      ],
      "metadata": {
        "id": "8orpAMHfTUDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ewv-zhphq1pB",
        "outputId": "acfee032-663e-4013-b899-4d4ecfa29e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-03 13:53:25,665] A new study created in memory with name: no-name-f8365d80-977a-4b46-ade9-b22b4df1946f\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:53:30,499] Trial 0 finished with value: 0.6387872982899436 and parameters: {'loss': 'exponential', 'learning_rate': 0.003919712424242074, 'max_depth': 1, 'n_estimators': 24}. Best is trial 0 with value: 0.6387872982899436.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:53:48,750] Trial 1 finished with value: 0.9086262408402886 and parameters: {'loss': 'exponential', 'learning_rate': 0.0031608275025105377, 'max_depth': 3, 'n_estimators': 68}. Best is trial 1 with value: 0.9086262408402886.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:54:12,959] Trial 2 finished with value: 0.9807040285601663 and parameters: {'loss': 'exponential', 'learning_rate': 0.3295750372732709, 'max_depth': 10, 'n_estimators': 66}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:54:17,317] Trial 3 finished with value: 0.9193120949983624 and parameters: {'loss': 'exponential', 'learning_rate': 0.00806865177831169, 'max_depth': 4, 'n_estimators': 19}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:55:48,215] Trial 4 finished with value: 0.9619360694052965 and parameters: {'loss': 'log_loss', 'learning_rate': 0.005123678383611137, 'max_depth': 17, 'n_estimators': 58}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:56:32,305] Trial 5 finished with value: 0.9799072141733843 and parameters: {'loss': 'log_loss', 'learning_rate': 0.19227580115303852, 'max_depth': 16, 'n_estimators': 50}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:58:45,031] Trial 6 finished with value: 0.9614640099792494 and parameters: {'loss': 'exponential', 'learning_rate': 0.007126270502175557, 'max_depth': 19, 'n_estimators': 70}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:59:36,324] Trial 7 finished with value: 0.9738791500463839 and parameters: {'loss': 'exponential', 'learning_rate': 0.07710472593343182, 'max_depth': 16, 'n_estimators': 35}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:59:41,132] Trial 8 finished with value: 0.9270582544626401 and parameters: {'loss': 'exponential', 'learning_rate': 0.004828674929275151, 'max_depth': 5, 'n_estimators': 20}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 13:59:45,098] Trial 9 finished with value: 0.9406634775820875 and parameters: {'loss': 'exponential', 'learning_rate': 0.10721783652193569, 'max_depth': 2, 'n_estimators': 39}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:00:56,837] Trial 10 finished with value: 0.9762631985942813 and parameters: {'loss': 'log_loss', 'learning_rate': 0.03110490948893767, 'max_depth': 10, 'n_estimators': 98}. Best is trial 2 with value: 0.9807040285601663.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:01:32,243] Trial 11 finished with value: 0.9810356348913807 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4229719668613913, 'max_depth': 12, 'n_estimators': 83}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:02:07,509] Trial 12 finished with value: 0.9788918410683023 and parameters: {'loss': 'log_loss', 'learning_rate': 0.4193853220066868, 'max_depth': 11, 'n_estimators': 91}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:02:37,336] Trial 13 finished with value: 0.9786794485834334 and parameters: {'loss': 'log_loss', 'learning_rate': 0.44975122285092534, 'max_depth': 11, 'n_estimators': 81}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:02:39,932] Trial 14 finished with value: 0.9407504899871788 and parameters: {'loss': 'log_loss', 'learning_rate': 0.03758124391174637, 'max_depth': 8, 'n_estimators': 3}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:03:23,163] Trial 15 finished with value: 0.9807396556866602 and parameters: {'loss': 'log_loss', 'learning_rate': 0.20117271488374966, 'max_depth': 13, 'n_estimators': 75}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:04:54,664] Trial 16 finished with value: 0.9481218794862202 and parameters: {'loss': 'log_loss', 'learning_rate': 0.001113971027542893, 'max_depth': 14, 'n_estimators': 83}. Best is trial 11 with value: 0.9810356348913807.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:05:43,993] Trial 17 finished with value: 0.9813670128435792 and parameters: {'loss': 'log_loss', 'learning_rate': 0.14514901808316996, 'max_depth': 13, 'n_estimators': 79}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:06:18,059] Trial 18 finished with value: 0.980141531043788 and parameters: {'loss': 'log_loss', 'learning_rate': 0.10495477422685069, 'max_depth': 8, 'n_estimators': 100}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:09:31,565] Trial 19 finished with value: 0.9676423474987702 and parameters: {'loss': 'log_loss', 'learning_rate': 0.01573516781440089, 'max_depth': 20, 'n_estimators': 87}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:10:35,870] Trial 20 finished with value: 0.9776592795190154 and parameters: {'loss': 'log_loss', 'learning_rate': 0.057207956736066976, 'max_depth': 13, 'n_estimators': 54}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:11:18,548] Trial 21 finished with value: 0.9812475706182174 and parameters: {'loss': 'log_loss', 'learning_rate': 0.21636239370516677, 'max_depth': 13, 'n_estimators': 75}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:12:07,653] Trial 22 finished with value: 0.9811073459024009 and parameters: {'loss': 'log_loss', 'learning_rate': 0.20422480678565585, 'max_depth': 14, 'n_estimators': 77}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:13:01,866] Trial 23 finished with value: 0.9806615500631926 and parameters: {'loss': 'log_loss', 'learning_rate': 0.15564100890216506, 'max_depth': 15, 'n_estimators': 63}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:14:04,201] Trial 24 finished with value: 0.9800337361482417 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2342531199703765, 'max_depth': 18, 'n_estimators': 76}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:15:59,713] Trial 25 finished with value: 0.9788331476611933 and parameters: {'loss': 'log_loss', 'learning_rate': 0.05469637216984658, 'max_depth': 15, 'n_estimators': 92}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:16:21,825] Trial 26 finished with value: 0.9793237057875355 and parameters: {'loss': 'log_loss', 'learning_rate': 0.13130041747838894, 'max_depth': 7, 'n_estimators': 74}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:17:25,394] Trial 27 finished with value: 0.9661336757191542 and parameters: {'loss': 'log_loss', 'learning_rate': 0.018559885894410762, 'max_depth': 13, 'n_estimators': 50}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:17:48,233] Trial 28 finished with value: 0.9802152974659523 and parameters: {'loss': 'log_loss', 'learning_rate': 0.24067959510099016, 'max_depth': 9, 'n_estimators': 62}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:19:10,311] Trial 29 finished with value: 0.9796550837397339 and parameters: {'loss': 'log_loss', 'learning_rate': 0.07245548522853493, 'max_depth': 14, 'n_estimators': 78}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:19:35,467] Trial 30 finished with value: 0.979594563300497 and parameters: {'loss': 'log_loss', 'learning_rate': 0.29382310004068035, 'max_depth': 12, 'n_estimators': 43}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:20:12,453] Trial 31 finished with value: 0.9793728072759726 and parameters: {'loss': 'log_loss', 'learning_rate': 0.49440461861399415, 'max_depth': 12, 'n_estimators': 87}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:20:54,547] Trial 32 finished with value: 0.9813249911046372 and parameters: {'loss': 'log_loss', 'learning_rate': 0.32402075725105883, 'max_depth': 12, 'n_estimators': 92}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:21:57,143] Trial 33 finished with value: 0.9809703184928082 and parameters: {'loss': 'log_loss', 'learning_rate': 0.15066489534640262, 'max_depth': 14, 'n_estimators': 93}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:22:46,245] Trial 34 finished with value: 0.9787934097124115 and parameters: {'loss': 'log_loss', 'learning_rate': 0.2983349873753685, 'max_depth': 17, 'n_estimators': 66}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:23:27,584] Trial 35 finished with value: 0.9796459485790943 and parameters: {'loss': 'log_loss', 'learning_rate': 0.0865267028931067, 'max_depth': 10, 'n_estimators': 72}. Best is trial 17 with value: 0.9813670128435792.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:24:29,870] Trial 36 finished with value: 0.9814681847476617 and parameters: {'loss': 'exponential', 'learning_rate': 0.16884597932065828, 'max_depth': 15, 'n_estimators': 96}. Best is trial 36 with value: 0.9814681847476617.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:25:26,987] Trial 37 finished with value: 0.9816835461597384 and parameters: {'loss': 'exponential', 'learning_rate': 0.3191348550835059, 'max_depth': 16, 'n_estimators': 96}. Best is trial 37 with value: 0.9816835461597384.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:26:26,367] Trial 38 finished with value: 0.9815867134569595 and parameters: {'loss': 'exponential', 'learning_rate': 0.33573010377262436, 'max_depth': 17, 'n_estimators': 97}. Best is trial 37 with value: 0.9816835461597384.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:27:51,904] Trial 39 finished with value: 0.9806814190375835 and parameters: {'loss': 'exponential', 'learning_rate': 0.14518742816189734, 'max_depth': 18, 'n_estimators': 100}. Best is trial 37 with value: 0.9816835461597384.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:29:55,162] Trial 40 finished with value: 0.9767699716307586 and parameters: {'loss': 'exponential', 'learning_rate': 0.04631413523327136, 'max_depth': 16, 'n_estimators': 88}. Best is trial 37 with value: 0.9816835461597384.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:30:55,104] Trial 41 finished with value: 0.9826080244164573 and parameters: {'loss': 'exponential', 'learning_rate': 0.34733478375023913, 'max_depth': 17, 'n_estimators': 95}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:31:57,049] Trial 42 finished with value: 0.9822238909115657 and parameters: {'loss': 'exponential', 'learning_rate': 0.29100019291298806, 'max_depth': 17, 'n_estimators': 96}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:33:08,894] Trial 43 finished with value: 0.9817027299970813 and parameters: {'loss': 'exponential', 'learning_rate': 0.34375070794532375, 'max_depth': 20, 'n_estimators': 97}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:34:19,842] Trial 44 finished with value: 0.982087548639021 and parameters: {'loss': 'exponential', 'learning_rate': 0.3450134060926725, 'max_depth': 20, 'n_estimators': 95}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:35:22,590] Trial 45 finished with value: 0.9819553171887639 and parameters: {'loss': 'exponential', 'learning_rate': 0.34729909066693226, 'max_depth': 20, 'n_estimators': 85}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:36:25,646] Trial 46 finished with value: 0.982218409815182 and parameters: {'loss': 'exponential', 'learning_rate': 0.39364742609659426, 'max_depth': 20, 'n_estimators': 86}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:37:21,806] Trial 47 finished with value: 0.981934991456341 and parameters: {'loss': 'exponential', 'learning_rate': 0.4735754762485172, 'max_depth': 19, 'n_estimators': 85}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:38:29,737] Trial 48 finished with value: 0.9817593679930463 and parameters: {'loss': 'exponential', 'learning_rate': 0.266760667847329, 'max_depth': 19, 'n_estimators': 90}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:39:20,190] Trial 49 finished with value: 0.9812069191533717 and parameters: {'loss': 'exponential', 'learning_rate': 0.3966487872029835, 'max_depth': 20, 'n_estimators': 69}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:40:10,332] Trial 50 finished with value: 0.972725150878597 and parameters: {'loss': 'exponential', 'learning_rate': 0.10983884154523288, 'max_depth': 18, 'n_estimators': 31}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:41:04,037] Trial 51 finished with value: 0.9821866651319597 and parameters: {'loss': 'exponential', 'learning_rate': 0.4987109916659152, 'max_depth': 19, 'n_estimators': 84}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:41:57,967] Trial 52 finished with value: 0.9817050137872414 and parameters: {'loss': 'exponential', 'learning_rate': 0.3889170801360746, 'max_depth': 19, 'n_estimators': 82}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:44:14,842] Trial 53 finished with value: 0.9362808842652796 and parameters: {'loss': 'exponential', 'learning_rate': 0.0015384840562267974, 'max_depth': 20, 'n_estimators': 85}. Best is trial 41 with value: 0.9826080244164573.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:45:06,857] Trial 54 finished with value: 0.9830177363711398 and parameters: {'loss': 'exponential', 'learning_rate': 0.49223830934579216, 'max_depth': 17, 'n_estimators': 94}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:45:57,150] Trial 55 finished with value: 0.98263520151936 and parameters: {'loss': 'exponential', 'learning_rate': 0.49942424073591435, 'max_depth': 17, 'n_estimators': 94}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:46:47,477] Trial 56 finished with value: 0.9825648607824357 and parameters: {'loss': 'exponential', 'learning_rate': 0.4811175927556799, 'max_depth': 17, 'n_estimators': 90}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:49:25,961] Trial 57 finished with value: 0.9653672357414985 and parameters: {'loss': 'exponential', 'learning_rate': 0.008721970026328955, 'max_depth': 17, 'n_estimators': 91}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:49:32,329] Trial 58 finished with value: 0.9601889699329891 and parameters: {'loss': 'exponential', 'learning_rate': 0.2615599162975571, 'max_depth': 17, 'n_estimators': 4}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:50:38,050] Trial 59 finished with value: 0.9807898990701777 and parameters: {'loss': 'exponential', 'learning_rate': 0.22247087475341795, 'max_depth': 18, 'n_estimators': 89}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:51:43,599] Trial 60 finished with value: 0.9815574809429131 and parameters: {'loss': 'exponential', 'learning_rate': 0.17937979650551708, 'max_depth': 16, 'n_estimators': 100}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:52:31,736] Trial 61 finished with value: 0.9827493910273538 and parameters: {'loss': 'exponential', 'learning_rate': 0.4771271213059908, 'max_depth': 18, 'n_estimators': 80}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:53:20,884] Trial 62 finished with value: 0.9820329660541998 and parameters: {'loss': 'exponential', 'learning_rate': 0.4208628216369927, 'max_depth': 18, 'n_estimators': 79}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:54:13,436] Trial 63 finished with value: 0.981633074397205 and parameters: {'loss': 'exponential', 'learning_rate': 0.40267548385696694, 'max_depth': 17, 'n_estimators': 94}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:54:59,194] Trial 64 finished with value: 0.9817034151341293 and parameters: {'loss': 'exponential', 'learning_rate': 0.26794817009943894, 'max_depth': 15, 'n_estimators': 81}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:55:44,830] Trial 65 finished with value: 0.9823931197624127 and parameters: {'loss': 'exponential', 'learning_rate': 0.4790854891977161, 'max_depth': 16, 'n_estimators': 89}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:56:32,676] Trial 66 finished with value: 0.9820685931806938 and parameters: {'loss': 'exponential', 'learning_rate': 0.48646484831895553, 'max_depth': 16, 'n_estimators': 90}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:57:40,082] Trial 67 finished with value: 0.9812516814405053 and parameters: {'loss': 'exponential', 'learning_rate': 0.21441892161599843, 'max_depth': 18, 'n_estimators': 94}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 14:59:41,863] Trial 68 finished with value: 0.9605228600543633 and parameters: {'loss': 'exponential', 'learning_rate': 0.0031998118168751546, 'max_depth': 15, 'n_estimators': 89}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:00:16,836] Trial 69 finished with value: 0.979008314366456 and parameters: {'loss': 'exponential', 'learning_rate': 0.2683250701438277, 'max_depth': 17, 'n_estimators': 45}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:00:20,385] Trial 70 finished with value: 0.8580386901458567 and parameters: {'loss': 'exponential', 'learning_rate': 0.011484850781654777, 'max_depth': 1, 'n_estimators': 99}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:00:34,229] Trial 71 finished with value: 0.9788607815221279 and parameters: {'loss': 'exponential', 'learning_rate': 0.39934687154754345, 'max_depth': 5, 'n_estimators': 93}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:01:19,348] Trial 72 finished with value: 0.981557252563897 and parameters: {'loss': 'exponential', 'learning_rate': 0.395157303446292, 'max_depth': 16, 'n_estimators': 80}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:02:15,877] Trial 73 finished with value: 0.9826249244636405 and parameters: {'loss': 'exponential', 'learning_rate': 0.4941399868481684, 'max_depth': 19, 'n_estimators': 88}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:03:09,650] Trial 74 finished with value: 0.9825125619877744 and parameters: {'loss': 'exponential', 'learning_rate': 0.4884041848434185, 'max_depth': 17, 'n_estimators': 96}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:04:02,951] Trial 75 finished with value: 0.9820153808699688 and parameters: {'loss': 'exponential', 'learning_rate': 0.4900619151634953, 'max_depth': 18, 'n_estimators': 88}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:05:17,078] Trial 76 finished with value: 0.9802876936140204 and parameters: {'loss': 'exponential', 'learning_rate': 0.19239279324985353, 'max_depth': 19, 'n_estimators': 92}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:06:10,941] Trial 77 finished with value: 0.982124546039611 and parameters: {'loss': 'exponential', 'learning_rate': 0.3730936933568405, 'max_depth': 16, 'n_estimators': 98}. Best is trial 54 with value: 0.9830177363711398.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:06:54,797] Trial 78 finished with value: 0.9830718621979289 and parameters: {'loss': 'exponential', 'learning_rate': 0.4960796113859799, 'max_depth': 15, 'n_estimators': 87}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:08:46,029] Trial 79 finished with value: 0.9715878233789772 and parameters: {'loss': 'exponential', 'learning_rate': 0.025142346314998443, 'max_depth': 15, 'n_estimators': 72}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:09:43,720] Trial 80 finished with value: 0.9814471738781909 and parameters: {'loss': 'exponential', 'learning_rate': 0.3071938851663516, 'max_depth': 18, 'n_estimators': 83}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:10:33,351] Trial 81 finished with value: 0.9822241192905816 and parameters: {'loss': 'exponential', 'learning_rate': 0.4990481972854681, 'max_depth': 17, 'n_estimators': 87}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:11:01,208] Trial 82 finished with value: 0.9810187348441975 and parameters: {'loss': 'exponential', 'learning_rate': 0.435499294589892, 'max_depth': 14, 'n_estimators': 55}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:12:06,612] Trial 83 finished with value: 0.9822499261193883 and parameters: {'loss': 'exponential', 'learning_rate': 0.33697804279648086, 'max_depth': 19, 'n_estimators': 92}. Best is trial 78 with value: 0.9830718621979289.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:12:55,963] Trial 84 finished with value: 0.983202494995074 and parameters: {'loss': 'exponential', 'learning_rate': 0.43644791604828764, 'max_depth': 15, 'n_estimators': 95}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:14:00,565] Trial 85 finished with value: 0.9817326476481758 and parameters: {'loss': 'exponential', 'learning_rate': 0.24703583814454136, 'max_depth': 17, 'n_estimators': 94}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:14:54,253] Trial 86 finished with value: 0.982198084082759 and parameters: {'loss': 'exponential', 'learning_rate': 0.29896361352947326, 'max_depth': 14, 'n_estimators': 98}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:15:49,614] Trial 87 finished with value: 0.9821389339176183 and parameters: {'loss': 'exponential', 'learning_rate': 0.35627043416938986, 'max_depth': 15, 'n_estimators': 96}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:16:59,494] Trial 88 finished with value: 0.98300974310558 and parameters: {'loss': 'exponential', 'learning_rate': 0.44605770618352447, 'max_depth': 18, 'n_estimators': 100}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:18:02,463] Trial 89 finished with value: 0.9821850664788478 and parameters: {'loss': 'exponential', 'learning_rate': 0.40703143828622607, 'max_depth': 18, 'n_estimators': 91}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:19:17,259] Trial 90 finished with value: 0.9818102965136117 and parameters: {'loss': 'exponential', 'learning_rate': 0.306317845724285, 'max_depth': 19, 'n_estimators': 100}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:20:12,830] Trial 91 finished with value: 0.9826687732347101 and parameters: {'loss': 'exponential', 'learning_rate': 0.41976290079806317, 'max_depth': 16, 'n_estimators': 95}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:21:13,201] Trial 92 finished with value: 0.9813569641668756 and parameters: {'loss': 'exponential', 'learning_rate': 0.4223757319814768, 'max_depth': 18, 'n_estimators': 94}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:21:59,109] Trial 93 finished with value: 0.9825685148466914 and parameters: {'loss': 'exponential', 'learning_rate': 0.3445278273868361, 'max_depth': 15, 'n_estimators': 86}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:22:57,837] Trial 94 finished with value: 0.9804939198654574 and parameters: {'loss': 'exponential', 'learning_rate': 0.22772513804917358, 'max_depth': 16, 'n_estimators': 87}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:23:42,902] Trial 95 finished with value: 0.9825057106172947 and parameters: {'loss': 'exponential', 'learning_rate': 0.3395597176583667, 'max_depth': 15, 'n_estimators': 82}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:24:34,178] Trial 96 finished with value: 0.9823565791198546 and parameters: {'loss': 'exponential', 'learning_rate': 0.2688079897362364, 'max_depth': 14, 'n_estimators': 98}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:25:06,156] Trial 97 finished with value: 0.9804998577198729 and parameters: {'loss': 'exponential', 'learning_rate': 0.35985014679075616, 'max_depth': 11, 'n_estimators': 84}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:26:14,615] Trial 98 finished with value: 0.9796333877332151 and parameters: {'loss': 'exponential', 'learning_rate': 0.12277537740680873, 'max_depth': 16, 'n_estimators': 78}. Best is trial 84 with value: 0.983202494995074.\n",
            "<ipython-input-8-4fc1e4efd6ae>:31: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
            "[I 2024-05-03 15:27:17,525] Trial 99 finished with value: 0.9807426246138683 and parameters: {'loss': 'exponential', 'learning_rate': 0.17148824318495162, 'max_depth': 15, 'n_estimators': 95}. Best is trial 84 with value: 0.983202494995074.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Train:     Test: \n",
              "0  0.991448  0.992692"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53d31812-89e2-49d9-abda-d75c88a91221\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train:</th>\n",
              "      <th>Test:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.991448</td>\n",
              "      <td>0.992692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53d31812-89e2-49d9-abda-d75c88a91221')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53d31812-89e2-49d9-abda-d75c88a91221 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53d31812-89e2-49d9-abda-d75c88a91221');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Train: \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9914478081917539,\n        \"max\": 0.9914478081917539,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9914478081917539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test: \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9926923282464192,\n        \"max\": 0.9926923282464192,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9926923282464192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import optuna\n",
        "\n",
        "df = pd.read_csv('prepared_train.csv')\n",
        "X = df.drop(['text_type'],axis=1)\n",
        "X['text'] = X['text'].fillna('space')\n",
        "y  = df['text_type'].replace({'ham':0,'spam':1})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# создаем трансформер для удобной предобработки данных\n",
        "vectorizer = CountVectorizer()\n",
        "scaler = StandardScaler()\n",
        "preprocessor = ColumnTransformer(\n",
        "  transformers=[('text', vectorizer, 'text'),('num', scaler, ['spam_symbols', 'not_spam_symbols', 'special_symbols', 'digits','text_len', 'words_count', 'emojis_count'])])\n",
        "def objective(trial):\n",
        "  param = {\n",
        "        \"loss\": trial.suggest_categorical(\"loss\", [\"log_loss\", \"exponential\"]),\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.5),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n",
        "  }\n",
        "  model = Pipeline(steps=[('preprocessor', preprocessor),('classifier', GradientBoostingClassifier(**param))])\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred_test = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  score = roc_auc_score(y_test,y_pred_test)\n",
        "\n",
        "  return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "y_pred_train = model.predict_proba(X_train)[:, 1]\n",
        "y_pred_test = model.predict_proba(X_test)[:, 1]\n",
        "results = pd.DataFrame({'Train: ':roc_auc_score(y_train, y_pred_train),'Test: ':roc_auc_score(y_test, y_pred_test)},index=['0'])\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters =  {'loss': 'exponential', 'learning_rate': 0.43644791604828764, 'max_depth': 15, 'n_estimators': 95}\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),('classifier', GradientBoostingClassifier(**parameters))])\n",
        "model.fit(X_train,y_train)\n",
        "y_pred_train = model.predict_proba(X_train)[:, 1]\n",
        "y_pred_test = model.predict_proba(X_test)[:, 1]\n",
        "results = pd.DataFrame({'Train: ':roc_auc_score(y_train, y_pred_train),'Test: ':roc_auc_score(y_test, y_pred_test)},index=['0'])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "WhViTxBvKqPA",
        "outputId": "d93da30c-0511-48f3-bf6c-9646fff6d113"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Train:     Test: \n",
              "0  0.999984  0.982644"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ea6933f-ea82-43f5-9b9d-e4d08f259fcb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train:</th>\n",
              "      <th>Test:</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999984</td>\n",
              "      <td>0.982644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ea6933f-ea82-43f5-9b9d-e4d08f259fcb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ea6933f-ea82-43f5-9b9d-e4d08f259fcb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ea6933f-ea82-43f5-9b9d-e4d08f259fcb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Train: \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9999835149236597,\n        \"max\": 0.9999835149236597,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9999835149236597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test: \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9826436515429515,\n        \"max\": 0.9826436515429515,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9826436515429515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}